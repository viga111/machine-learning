{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e75f83",
   "metadata": {},
   "source": [
    "**<font color=black size=5>K近邻</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106082c",
   "metadata": {},
   "source": [
    "**1** 介绍K近邻算法的基本原理\n",
    "\n",
    "**2** 介绍K近邻算法的KDTree实现方法\n",
    "\n",
    "**3** 通过简单案例和鸢尾花分类案例，对比分析本文算法和sklearn的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afa2518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.023024Z",
     "start_time": "2021-09-22T00:11:40.310752Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b3be5b",
   "metadata": {},
   "source": [
    "**<font color=black size=4>1 K近邻算法</font>** \n",
    "\n",
    "K近邻算法多用于分类任务，本文仅就其分类问题进行讨论。**基本思想**：给定一个已知标签的数据集，对一个输入的未知标签的样本，计算其与数据集中各样本之间的距离，找出与之距离最小的$k$个样本；统计这$k$个样本的类别，以多数服从少数的原则，最终确定未知样本的分类标签。算法的三个基本要素如下：\n",
    "\n",
    "+ **$k$值：** $k$值越大，模型越简单；反之，越复杂。试想：若$k$取数据集的样本总数$n$，那么无论输入的未知样本是什么，最终得到的其分类标签都是数据集中占比最大的那一类的标签，这样的模型是非常简单的。\n",
    "\n",
    "+ **距离度量方法**：不同的距离度量确定的最邻近点通常是不同的。一般选择$Minkowski$距离，其定义为：$$ L_p(x_i, x_j)=(\\sum_{l=1}^{m}|x_i^{(l)}- x_j^{(l)}|^p)^{\\frac{1}{p}} $$\n",
    "其中：$p>=1$；$m$为特征的维数；$l$为第几维。<br>\n",
    "当$p=2$时，为欧氏距离：$ L_2(x_i, x_j)=(\\sum_{l=1}^{m}|x_i^{(l)}- x_j^{(l)}|^2)^{\\frac{1}{2}} $<br>\n",
    "当$p=1$时，为曼哈顿距离：$ L_1(x_i, x_j)=\\sum_{l=1}^{m}|x_i^{(l)}- x_j^{(l)}| $<br>\n",
    "当$p=\\infty$时，为各个维度下距离的最大值：$ L_\\infty(x_i, x_j)=max|x_i^{(l)}- x_j^{(l)}| $\n",
    "\n",
    "+ **分类决策规则**：一般是采用多数表决的规则，即由输入的未知样本的k个邻近样本中的多数类决定未知样本的类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e315517",
   "metadata": {},
   "source": [
    "**<font color=black size=4>2 KDTree</font>** \n",
    "\n",
    "K近邻算法的思想很简单，但存在的问题是：当样本数量较大时，为预测一个未知样本的类别标签，需要遍历计算其与所有\n",
    "\n",
    "样本之间的距离（线性搜索），这无疑会造成较大的时间开销。通过构造KDTree，减少计算距离的次数，提高算法效率。\n",
    "\n",
    "\n",
    "**<font color=black size=3.5>2.1 KDTree构造</font>** \n",
    "\n",
    "+ **两个基本操作：**<br>\n",
    "1) 计算划分维度： $ l=j \\  \\% \\ m $。$\\%$为取模运算；$j$的起始值为0，每完成一次划分$j=j+1$；$m$为特征的维数<br>\n",
    "2) 计算划分点： 按$l$维的值对$X$从小到大排序，取中间点作为划分点。排序后中间点索引的计算方法为：$len(X)\\ // \\ 2$<br>\n",
    "+ **示例：** 给定数据集$X = [[2, 3], [5, 4], [9, 6], [4, 7], [8, 1], [7, 2]]$，构造一个kd树。<br>\n",
    "1) 第1次划分： <br>\n",
    "$ l_1=0 \\  \\% \\ 2 = 0$，也就是划分维度为第0维；<br>\n",
    "按第0维元素值对$X$排序的结果为$X = [[2, 3], [4, 7], [5, 4], [7, 2], [8, 1], [9, 6]]$；<br>\n",
    "划分点的索引为$len(X)\\ // \\ 2 = 6 \\ // \\ 2 = 3$，对应$[7, 2]$，存储到根节点；\n",
    "将$[7, 2]$左侧的点存储到左子树，右侧的点存储到右子树。<br>\n",
    "<img src=\"../src/kdtree1.png\" width=280, heigth=200>\n",
    "2) 第2次划分： <br>\n",
    "$j = j + 1$，即$ l_2=1 \\  \\% \\ 2 = 1$；<br>\n",
    "对第1次划分得到的左右子树，分别进行同样的划分操作，得到新的左右子树。<br>\n",
    "<img src=\"../src/kdtree2.png\" width=280, heigth=200>\n",
    "3) 第3次划分： <br>\n",
    "$j = j + 1$，即$ l_3=2 \\  \\% \\ 2 = 0$；<br>\n",
    "划分后发现所有叶节点中只有一个点，因而无法继续划分，划分停止，得到最终的KDTree。\n",
    "<img src=\"../src/kdtree3.png\" width=280, heigth=200><br>\n",
    "<font color=red>注：可以发现上述过程，划分维度是交替进行的，因此可以称为交替维度划分法。除此之外，还可以\n",
    "采用最大方差法，即：每一次划分计算各个维度上的方差，取方差最大的维度作为该次的划分维度。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f8d71",
   "metadata": {},
   "source": [
    "**<font color=black size=3.5>2.2 KDTree搜索</font>** <br>\n",
    "+ 上述的二维数据集构造的KDTree可以对应用如下二维平面的划分来表达，每一次划分即对应在该次的划分维度上根据划分点将平面切割。如下图所示，第$1$次划分在$l=0$维度的$x^{(1)}=7$处将平面切割为左右两个区域。\n",
    "<img src=\"../src/kdtree4.png\" width=280, heigth=200><br>\n",
    "+ **搜索过程**<br>\n",
    "以寻找点(2.5, 4.5)的最邻近点为例：<br>\n",
    "1) 按上述创建的KDTree从根节点开始判断，直至达到叶节点，可以得到(2.5, 4.5)的第一个候选最邻近点为(4, 7)，对应的欧式距离$d_{min}$为2.915；<br>\n",
    "2) 回溯。(4, 7)的根节点为(5, 4)，计算(2.5, 4.5)与(5, 4)的距离为2.550<2.915，因此(2.5, 4.5)的最邻近点更新为(5, 4)，$d_{min}$更新为2.550；由于不清楚(5, 4)的左子树中有没有更近的点，因此需要做一步判断：计算(5, 4)的划分维度$l$下，(2.5, 4.5)与(5, 4)在$l$上的距离$d_l$，若$d_l<d_{min}$，则需要进入(5, 4)的右子树重复1)、2)的搜索过程，反之则不需要；在本例中，(5, 4)的划分维度$l=1$，则$d_l=|4.5-4|=0.5<2.550$，因此进入左子树进行搜索，计算(2.5, 4.5)与(2, 3)的距离为1.581，因此更新最邻近点为(2, 3)，$d_{min}=1.581$。<br>\n",
    "<img src=\"../src/kdtree5.png\" width=280, heigth=200><br>\n",
    "3)继续向上回溯。(5, 4)的根节点为(7, 2)，计算(2.5, 4.5)与(7, 2)的距离为5.148>1.581，因此不更新最邻近点与$d_{min}$。同样地，判断$d_l$和$d_{min}$的大小关系，发现$d_l= 4.5 > d_{min}=1.581$，因此不需要再进入\n",
    "(7, 2)的右子树进行搜索。本例中(7, 2)为整体树的根节点，因此到此搜索也就停止，最终得到的最邻近点为(2, 3)，最邻近距离为1.581。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a1d2c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.039024Z",
     "start_time": "2021-09-22T00:11:42.026022Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"kd树中的一个节点\"\"\"\n",
    "\n",
    "    def __init__(self, seg_axis, seg_point, left=None, right=None):\n",
    "        self.seg_axis = seg_axis  # int 划分维度\n",
    "        self.seg_point = seg_point  # list 划分点\n",
    "        self.left = left  # class 左子树\n",
    "        self.right = right  # class 右子树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "108a216c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.055026Z",
     "start_time": "2021-09-22T00:11:42.042025Z"
    }
   },
   "outputs": [],
   "source": [
    "class KDTree(object):\n",
    "    \"\"\"kd树类\"\"\"\n",
    "\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        def create(X, depth=0):\n",
    "            \"\"\"递归创建kd树\n",
    "            Parameters\n",
    "            ----------\n",
    "            X: list 样本\n",
    "            depth: int 树的深度 默认为0\n",
    "            \"\"\"\n",
    "            if not X:\n",
    "                return\n",
    "\n",
    "            # 交替轴法确定划分维度\n",
    "            k = len(X[0])\n",
    "            ax = depth % k\n",
    "            sort_X = sorted(X, key=lambda x: x[ax])\n",
    "            mid = len(X) // 2\n",
    "\n",
    "            return Node(seg_axis=ax,\n",
    "                        seg_point=sort_X[mid],\n",
    "                        left=create(sort_X[:mid], depth + 1),\n",
    "                        right=create(sort_X[mid + 1:], depth + 1))\n",
    "\n",
    "        self.root = create(X, 0)\n",
    "\n",
    "    def query(self, x, k=1, p=2):\n",
    "        \"\"\"kd树查询目标点的k个最邻近点\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: list 目标点\n",
    "        k: int 最邻近点个数 默认为1\n",
    "        p: int 距离度量方法 默认为2 代表欧式距离\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        dist: list k个最邻近点距离（由大到小排列）\n",
    "        ind: list 对应dist的k个最邻近点在X中的索引\n",
    "        \"\"\"\n",
    "        self.knn = [(-np.inf, None)] * k\n",
    "\n",
    "        def search_knn(node):\n",
    "            \"\"\"query方法的辅助方法。用于访问kd树的结点，并计算结点与目标的距离，\n",
    "            确定k个最邻近的点。\n",
    "            Parameters\n",
    "            ----------\n",
    "            node: class kd树的结点\n",
    "            \"\"\"\n",
    "            if node is not None:\n",
    "                ax = node.seg_axis\n",
    "                ax_diff = abs(x[ax]-node.seg_point[ax])  # 目标点和结点在ax维度下的距离\n",
    "\n",
    "                if x[ax] < node.seg_point[ax]:\n",
    "                    search_knn(node.left)\n",
    "                else:\n",
    "                    search_knn(node.right)\n",
    "\n",
    "                # 计算目标点与结点的距离\n",
    "                d = np.linalg.norm(np.array(x)-np.array(node.seg_point), p)\n",
    "\n",
    "                # 利用堆结构存储距离和划分点信息\n",
    "                heapq.heappushpop(self.knn, (-d, node.seg_point))\n",
    "\n",
    "                # 回溯过程中，是否需要进入另一子区域的判断\n",
    "                if ax_diff < -self.knn[0][0]:\n",
    "                    if x[ax] < node.seg_point[ax]:\n",
    "                        search_knn(node.right)\n",
    "                    else:\n",
    "                        search_knn(node.left)\n",
    "\n",
    "        search_knn(self.root)\n",
    "        self.knn.sort(reverse=True)  # 对k个邻近点进行排序（也可不加这行代码）\n",
    "        \n",
    "        dist = []\n",
    "        ind = []\n",
    "        for item in self.knn:\n",
    "            dist.append(abs(item[0]))\n",
    "            ind.append(self.X.index(item[1]))\n",
    "\n",
    "        return dist, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390a4283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.071027Z",
     "start_time": "2021-09-22T00:11:42.058025Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyKNeighborsClassifier(KDTree):\n",
    "    \"\"\"K近邻分类器\"\"\"\n",
    "\n",
    "    def __init__(self, X, y, k=1, p=2):\n",
    "        super(MyKNeighborsClassifier, self).__init__(X)  # 继承父类的构造方法\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "        self.p = p\n",
    "\n",
    "    def kneighbors(self, x, k=1):\n",
    "        \"\"\"获取目标点的k个最邻近点\"\"\"\n",
    "        neigh_dist, neigh_ind = self.query(x, k)\n",
    "\n",
    "        return neigh_dist, neigh_ind\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"预测目标点的分类标签\"\"\"\n",
    "        _, neigh_ind = self.query(x, self.k)\n",
    "\n",
    "        # 多数服从少数的投票方法\n",
    "        vote = {}\n",
    "        for i in neigh_ind:\n",
    "            vote[self.y[i]] = vote.get(self.y[i], 0) + 1\n",
    "        out = sorted(vote.items(), key=lambda s: s[1], reverse=True)\n",
    "\n",
    "        return out[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c5cf4",
   "metadata": {},
   "source": [
    "**<font color=black size=4>3 案例</font>** \n",
    "\n",
    "**<font color=black size=3.5>3.1 简单案例</font>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d2285f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.087027Z",
     "start_time": "2021-09-22T00:11:42.074028Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "X = [[2, 3], [5, 4], [9, 6], [4, 7], [8, 1], [7, 2]]\n",
    "y = [0, 0, 1, 1, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873c6ea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.103029Z",
     "start_time": "2021-09-22T00:11:42.089030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本文算法\n",
      "-------\n",
      "最邻近点的距离： [1.5811388300841898, 2.5495097567963922, 2.9154759474226504]\n",
      "最邻近点的索引： [0, 1, 3]\n",
      "预测类别： 0\n"
     ]
    }
   ],
   "source": [
    "# 本文算法\n",
    "clf = MyKNeighborsClassifier(X, y, k=3)\n",
    "neigh_dist, neigh_ind = clf.kneighbors([2.5, 4.5], k=3)\n",
    "print('本文算法')\n",
    "print('-------')\n",
    "print('最邻近点的距离：', neigh_dist)\n",
    "print('最邻近点的索引：', neigh_ind)\n",
    "print('预测类别：', clf.predict([2.5, 4.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b78a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.135032Z",
     "start_time": "2021-09-22T00:11:42.107030Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn\n",
      "-------\n",
      "最邻近点的距离： [[1.58113883 2.54950976 2.91547595]]\n",
      "最邻近点的索引： [[0 1 3]]\n",
      "预测类别： [0]\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "neigh = KNeighborsClassifier(n_neighbors=3, algorithm='kd_tree')\n",
    "neigh.fit(X, y)\n",
    "dist, ind = neigh.kneighbors(np.array([[2.5, 4.5]]), n_neighbors=3)\n",
    "print('sklearn')\n",
    "print('-------')\n",
    "print('最邻近点的距离：', dist)\n",
    "print('最邻近点的索引：', ind)\n",
    "print('预测类别：', neigh.predict([[2.5, 4.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50b9c0",
   "metadata": {},
   "source": [
    "**<font color=black size=3.5>3.2 鸢尾花分类</font>** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b83533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.151033Z",
     "start_time": "2021-09-22T00:11:42.138031Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "iris = load_iris()\n",
    "X2 = iris.data\n",
    "y2 = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "248f7ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.167034Z",
     "start_time": "2021-09-22T00:11:42.153032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本文算法\n",
      "-------\n",
      "最邻近点的距离： [3.7376463182061515, 3.753664875824692, 3.7589892258425004]\n",
      "最邻近点的索引： [8, 38, 42]\n",
      "预测类别： 0\n"
     ]
    }
   ],
   "source": [
    "# 本文算法\n",
    "X2_copy = X2.copy().tolist()  # 转换成本文算法要求的数据类型\n",
    "y2_copy = y2.copy().tolist()\n",
    "\n",
    "clf2 = MyKNeighborsClassifier(X2_copy, y2_copy, k=3)\n",
    "neigh_dist2, neigh_ind2 = clf2.kneighbors([2, 3, 2, 3], 3)\n",
    "print('本文算法')\n",
    "print('-------')\n",
    "print('最邻近点的距离：', neigh_dist2)\n",
    "print('最邻近点的索引：', neigh_ind2)\n",
    "print('预测类别：', clf2.predict([2, 3, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c2ca450",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T00:11:42.183037Z",
     "start_time": "2021-09-22T00:11:42.170036Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn\n",
      "-------\n",
      "最邻近点的距离： [[3.73764632 3.75366488 3.75898923]]\n",
      "最邻近点的索引： [[ 8 38 42]]\n",
      "预测类别： [0]\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "neigh2 = KNeighborsClassifier(n_neighbors=3, algorithm='kd_tree')\n",
    "neigh2.fit(X2, y2)\n",
    "dist2, ind2 = neigh2.kneighbors(np.array([[2, 3, 2, 3]]), n_neighbors=3)\n",
    "print('sklearn')\n",
    "print('-------')\n",
    "print('最邻近点的距离：', dist2)\n",
    "print('最邻近点的索引：', ind2)\n",
    "print('预测类别：', neigh2.predict([[2, 3, 2, 3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d79b5ce",
   "metadata": {},
   "source": [
    "可以看出：本文算法与sklearn算法得到的结果一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b6a30d",
   "metadata": {},
   "source": [
    "<font color=red>*注：本文重在通过代码理解算法的工作原理，仅供学习使用。更多关于算法相关的资料可以在参考里找到。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015d271e",
   "metadata": {},
   "source": [
    "**<font color=black size=4>参考</font>**\n",
    "\n",
    "1 李航. (2012) 统计学习方法. 清华大学出版社, 北京.\n",
    "\n",
    "2 [sklearn文档](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "379.667px",
    "left": "868px",
    "right": "20px",
    "top": "109px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
