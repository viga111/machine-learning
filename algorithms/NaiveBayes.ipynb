{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f96bc6",
   "metadata": {},
   "source": [
    "**<font color=black size=5>朴素贝叶斯</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69520a",
   "metadata": {},
   "source": [
    "**1** 介绍朴素贝叶斯算法的基本原理\n",
    "\n",
    "**2** 手动实现传统朴素贝叶斯模型MyCatogricalNB，并通过西瓜分类案例，对比分析本文算法与sklearn库的结果\n",
    "\n",
    "**3** 手动实现高斯朴素贝叶斯模型MyGaussianNB，并通过鸢尾花分类案例，对比分析本文算法与sklearn库的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cadf61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T11:58:32.395999Z",
     "start_time": "2021-09-21T11:58:30.495326Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from scipy.special import logsumexp\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb96e4",
   "metadata": {},
   "source": [
    "**<font color=black size=4>1 算法概述</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e9795",
   "metadata": {},
   "source": [
    "**1.1 提出问题**\n",
    "\n",
    "给定已知分类标签的数据集$\\mathop D \\limits_{n \\times (d+1)}$，输入一个未知分类标签的的特征向量$\\mathop x \\limits_{1 \\times d} =(x^{(1)},x^{(2)},...,x^{(d)})$，问输出的分类标签$y$是什么？\n",
    "\n",
    "**1.2 贝叶斯定理**\n",
    "\n",
    "根据贝叶斯定理，上述问题可以转换为如下数学表达：\n",
    "$$P(Y=c_k|X=x) = \\frac{P(X=x|Y=c_k)P(Y=c_k)}{P(X=x)}\\tag{1}$$\n",
    "其中：$P(Y=c_k)$是先验概率；$P(X=x|Y=c_k)$是条件概率。需要求解的问题可以理解为求出在输入$x$的条件下，$y$是第$k$类的概率，其中的最大概率所对应的类别即为最终输出的分类标签。\n",
    "\n",
    "**1.3 朴素贝叶斯**\n",
    "朴素贝叶斯**假设特征之间条件独立**，则上述公式可以进一步变换为：\n",
    "\n",
    "$$P(Y=c_k|X=x) = \\frac{P(X=x|Y=c_k)P(Y=c_k)}{P(X=x)}=\\frac{P(Y=c_k) \\prod_{j=1}^{d}P(X^{(j)}=x^{(j)}|Y=c_k)}{P(X=x)}\\tag{2}$$\n",
    "其中：$x^{(j)}$表示$x$的第$j$个取值。\n",
    "\n",
    "**1.4 模型求解**\n",
    "\n",
    "由式(2)可知，对于一个$x$来说$P(x)$是定值，因此要**求最大概率，只需要比较分子的大小**，因此可以进一步简化问题为：求出$max[P(Y=c_k) \\prod_{j=1}^{d}P(X^{(j)}=x^{(j)}|Y=c_k)]$，其对应的类别$c_k$即为最终$x$的分类标签。\n",
    "\n",
    "那么问题是：如何计算$P(Y=c_k)$和$P(X^{(j)}=x^{(j)}|Y=c_k)$？\n",
    "\n",
    "**（1）类别型特征**\n",
    "\n",
    "（1a）极大似然估计\n",
    "\n",
    "$$P(Y=c_k)=\\frac{\\sum_{i=1}^N I(y_i=c_k)}{N}\\tag{3}$$\n",
    "\n",
    "$$P(X^{(j)}=a_{jl}|Y=c_k)=\\frac{\\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl},y_i=c_k)}{\\sum_{i=1}^{N}I(y_i=c_k)}\\tag{4}$$\n",
    "\n",
    "其中：$I$为指示函数，满足括号内条件则返回1，反之则返回0；$a_{jl}$为所有样本中第$j$个特征的第$l$个取值，$x^{(j)}$可能取值的集合为$\\{a_{j1},a_{j2},...,a_{jS_j}\\}$；$x_i^{(j)}$为第$i$个样本的第$j$个特征的取值；$N$为样本总数。详细推导见附录。\n",
    "\n",
    "（1b）贝叶斯估计\n",
    "\n",
    "使用极大似然估计可能会出现所估计的概率值为0的情况，这会对计算后验概率造成影响。因而我们采用贝叶斯估计解决这\n",
    "\n",
    "一问题。先验概率和条件概率的贝叶斯估计分别为\n",
    "\n",
    "$$P_\\lambda(Y=c_k)=\\frac{\\sum_{i=1}^N I(y_i=c_k)+\\lambda}{N+K\\lambda}\\tag{5}$$\n",
    "\n",
    "$$P_\\lambda(X^{(j)}=a_{jl}|Y=c_k)=\\frac{\\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl},y_i=c_k)+\\lambda}{\\sum_{i=1}^{N}I(y_i=c_k)+S_j\\lambda}\\tag{6}$$\n",
    "\n",
    "当$\\lambda=1$时，称为拉普拉斯平滑。\n",
    "\n",
    "**（2）连续型特征**\n",
    "\n",
    "通常假设在$Y=c_k$的条件下，$x$服从某种分布（如高斯分布），利用概率密度函数来计算$P(X^{(j)}=x^{(j)}|Y=c_k)$，$P(Y=c_k)$的计算采用极大似然估计。\n",
    "\n",
    "<font color=blue>更多关于朴素贝叶斯的知识见参考。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d59090",
   "metadata": {},
   "source": [
    "**<font color=black size=4>2 传统朴素贝叶斯</font>**\n",
    "\n",
    "**<font color=black size=3.5>2.1 手动实现</font>**\n",
    "\n",
    "传统朴素贝叶斯一般处理的是类别型数据，sklearn中提供了[sklearn.naive_bayes.CategoricalNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB)来处理此类问题。\n",
    "\n",
    "本文手动实现传统朴素贝叶斯算法，部分实现细节参考sklearn中的相关源码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65319a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T11:58:32.428002Z",
     "start_time": "2021-09-21T11:58:32.399003Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyCategoricalNB(object):\n",
    "    \"\"\"传统朴素贝叶斯    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha: float 拉普拉斯平滑因子 默认值为1\n",
    "    priors: ndarray of shape (n_classes,) 类别的先验概率，若不指定则根据数据自适应计算\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    class_prior_: ndarray of shape (n_classes,) \n",
    "        每个类别的概率\n",
    "    class_log_prior_: ndarray of shape (n_classes,) \n",
    "        每个类别的概率(log)\n",
    "    classes_: ndarray of shape (n_classes,) \n",
    "        已知数据集的分类标签\n",
    "    class_count_: ndarray of shape (n_classes,) \n",
    "        每个类标签对应的样本个数\n",
    "    n_features_: int \n",
    "        数据集中的特征个数\n",
    "    n_categories_: ndarray of shape (n_features,) \n",
    "        每个特征可取值的个数\n",
    "    category_count_: list of arrays of shape (n_features,) \n",
    "        其中每个feature对应的array的形状为(n_classes, n_categories),\n",
    "        对应存储每个类别下该特征的每个取值的样本个数。\n",
    "    feature_log_prob_: list of arrays of shape (n_features,)\n",
    "        其中每个feature对应的array的形状为(n_classes, n_categories),\n",
    "        对应存储每个类别下该特征的每个取值的条件概率。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1.0, priors=None):\n",
    "        self.alpha = alpha\n",
    "        self.class_prior_ = priors\n",
    "        self.class_log_prior_ = None\n",
    "        self.classes_ = None\n",
    "        self.class_count_ = None\n",
    "        self.n_features_ = None\n",
    "        self.n_categories_ = None\n",
    "        self.category_count_ = []\n",
    "        self.feature_log_prob_ = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"拟合传统朴素贝叶斯模型\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "        y: ndarray of shape (n_samples,) 样本标签\n",
    "        \"\"\"\n",
    "        c = dict(Counter(y))\n",
    "        self.classes_ = np.array(list(c.keys()))\n",
    "        self.class_count_ = np.array(list(c.values()))\n",
    "\n",
    "        # 估计先验概率时不使用拉普拉斯平滑\n",
    "        if self.class_prior_ is None:\n",
    "            self.class_prior_ = self.class_count_ / X.shape[0]\n",
    "        self.class_log_prior_ = np.log(self.class_prior_)\n",
    "\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.n_categories_ = np.array([len(np.unique(X[:, i]))\n",
    "                                       for i in range(self.n_features_)])\n",
    "\n",
    "        self.category_count_ = self._update_category_count(X, y)\n",
    "\n",
    "        self.feature_log_prob_ = self._update_feature_log_prob(self.alpha)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"预测分类标签\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: ndarray of shape (n_samples,) 分类标签\n",
    "        \"\"\"\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "        return self.classes_[np.argmax(jll, axis=1)]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"预测归一化概率\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: ndarray of shape (n_samples, n_classes) 归一化概率\n",
    "        \"\"\"\n",
    "        return np.exp(self.predict_log_proba(X))\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        \"\"\"预测归一化概率(log)\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: ndarray of shape (n_samples, n_classes) 归一化概率(log)\n",
    "        \"\"\"\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "\n",
    "        # 归一化概率 e.g. log(pi / (p1+p2+...+pn)), i=1,2,...,n, n=n_classes\n",
    "        log_prob_x = logsumexp(jll, axis=1)\n",
    "        out = jll - np.atleast_2d(log_prob_x).T\n",
    "        return out\n",
    "\n",
    "    def _update_category_count(self, X, y):\n",
    "        \"\"\"更新每个类别下每个特征的每个取值的样本个数\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "        y:  ndarray of shape (n_samples,) 样本标签\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        category_count_: list of arrays of shape (n_features,) \n",
    "            更新后的每个类别下每个特征的每个取值的样本个数\n",
    "        \"\"\"\n",
    "        for i in range(self.n_features_):\n",
    "            arr = np.empty(shape=(len(self.classes_), self.n_categories_[i]))\n",
    "            valid_categories = np.unique(X[:, i])\n",
    "            for j in range(len(self.classes_)):\n",
    "                c_f = Counter(X[y == self.classes_[j]][:, i])\n",
    "                for k in range(self.n_categories_[i]):\n",
    "                    arr[j][k] = c_f[valid_categories[k]]\n",
    "            self.category_count_.append(arr)\n",
    "        return self.category_count_\n",
    "\n",
    "    def _update_feature_log_prob(self, alpha):\n",
    "        \"\"\"更新特征取值的条件概率(log)\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha: float 拉普拉斯平滑因子\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        feature_log_prob_: list of arrays of shape (n_features,) \n",
    "            更新后的特征取值的条件概率(log)\n",
    "        \"\"\"\n",
    "        for i in range(self.n_features_):\n",
    "            smoothed_cat_count = self.category_count_[i] + alpha\n",
    "            smoothed_class_count = smoothed_cat_count.sum(axis=1)\n",
    "            self.feature_log_prob_.append(np.log(smoothed_cat_count) -\n",
    "                                          np.log(smoothed_class_count.reshape(-1, 1)))\n",
    "        return self.feature_log_prob_\n",
    "\n",
    "    def _joint_log_likelihood(self, X):\n",
    "        \"\"\"计算联合概率(log)\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        total_ll: ndarray of shape (n_samples, n_classes) 联合概率(log)\n",
    "        \"\"\"\n",
    "        jll = np.zeros((X.shape[0], len(self.class_count_)))\n",
    "        for i in range(self.n_features_):\n",
    "            indices = X[:, i]\n",
    "            jll += self.feature_log_prob_[i][:, indices].T\n",
    "        total_ll = jll + self.class_log_prior_\n",
    "        return total_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249db911",
   "metadata": {},
   "source": [
    "**<font color=black size=3.5>2.2 西瓜分类案例</font>**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf93a52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T11:58:32.460016Z",
     "start_time": "2021-09-21T11:58:32.431003Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据准备 来源于《机器学习》-周志华 西瓜数据集2.0\n",
    "data = pd.read_csv('./data/Watermelon/Watermelon2.txt', index_col=0)\n",
    "data = np.array(data)\n",
    "\n",
    "# 数据编码\n",
    "oe = OrdinalEncoder(dtype=int)  # 这里注意由于是类别型数据，因为编码时设置为int类型\n",
    "data_encoded = oe.fit_transform(data)\n",
    "X_encoded = data_encoded[:, :-1]\n",
    "y_encoded = data_encoded[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ff8500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T11:58:32.476020Z",
     "start_time": "2021-09-21T11:58:32.462018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本文算法\n",
      "-------\n",
      "预测概率(log)\n",
      " [[-0.09636785 -2.38737967]\n",
      " [-0.03479499 -3.37562894]]\n",
      "预测概率\n",
      " [[0.9081299 0.0918701]\n",
      " [0.9658034 0.0341966]]\n",
      "类别对应\n",
      " [1 0]\n",
      "预测类别\n",
      " [1 1]\n"
     ]
    }
   ],
   "source": [
    "# 本文算法\n",
    "myclf = MyCategoricalNB()\n",
    "myclf.fit(X_encoded, y_encoded)\n",
    "\n",
    "X_encoded_test = np.array([[2, 2, 1, 1, 0, 0], [0, 2, 0, 1, 0, 0]])\n",
    "print('本文算法')\n",
    "print('-------')\n",
    "print('预测概率(log)\\n', myclf.predict_log_proba(X_encoded_test))\n",
    "print('预测概率\\n', myclf.predict_proba(X_encoded_test))\n",
    "print('类别对应\\n', myclf.classes_)\n",
    "print('预测类别\\n', myclf.predict(X_encoded_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "044a16e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T11:58:32.508019Z",
     "start_time": "2021-09-21T11:58:32.479019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn\n",
      "-------\n",
      "预测概率(log)\n",
      " [[-2.38737967 -0.09636785]\n",
      " [-3.37562894 -0.03479499]]\n",
      "预测概率\n",
      " [[0.0918701 0.9081299]\n",
      " [0.0341966 0.9658034]]\n",
      "类别对应\n",
      " [0 1]\n",
      "预测类别\n",
      " [1 1]\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X_encoded, y_encoded)\n",
    "\n",
    "print('sklearn')\n",
    "print('-------')\n",
    "print('预测概率(log)\\n', clf.predict_log_proba(X_encoded_test))\n",
    "print('预测概率\\n', clf.predict_proba(X_encoded_test))\n",
    "print('类别对应\\n', clf.classes_)\n",
    "print('预测类别\\n', clf.predict(X_encoded_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e3071",
   "metadata": {},
   "source": [
    "可以看出，本文算法与sklearn得到的结果一致，只是结果的输出形式有些许差别，这与实际的编码逻辑有关，但不影响\n",
    "\n",
    "结果的数值。\n",
    "\n",
    "**<font color=red>说明：</font>**在sklearn 0.24版本中，增加了一个新参数[min_categories](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB)，本文在复现过程中不关注这个参数相关的方法，\n",
    "\n",
    "重在复现基本的模型，以帮助理解模型的思想和处理过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fdadaf",
   "metadata": {},
   "source": [
    "**<font color=black size=4>3 高斯朴素贝叶斯</font>**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9117b1",
   "metadata": {},
   "source": [
    "高斯朴素贝叶斯假设特征条件独立且服从高斯分布，则：\n",
    "$$P(X^{(j)}=x^{(j)} | Y=c_k)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2_{jk}}}exp(-\\frac{(x_i - \\mu_{jk})^2}{2 \\sigma^2_{jk}})\\tag{7}$$\n",
    "其中：$\\sigma^2_{jk}$可以用第$k$类样本中第$j$个特征的方差来估计；$\\mu_{jk}$可以用第$k$类样本中第$j$个特征的均值来估计；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67766d0",
   "metadata": {},
   "source": [
    "**<font color=black size=3.5>3.1 手动实现</font>**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ec201e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T11:58:32.540025Z",
     "start_time": "2021-09-21T11:58:32.511021Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyGaussianNB(object):\n",
    "    \"\"\"高斯朴素贝叶斯    \n",
    "    Parameters\n",
    "    ----------\n",
    "    priors: ndarray of shape (n_classes,) \n",
    "        类别的先验概率，若不指定则根据数据自适应计算\n",
    "    var_smoothing: float \n",
    "        为提高计算的稳定性所设定的方差平滑因子\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    class_prior_: ndarray of shape (n_classes,) \n",
    "        每个类别的概率\n",
    "    var_smoothing: float \n",
    "        方差平滑因子\n",
    "    classes_: ndarray of shape (n_classes,) \n",
    "        已知数据集的分类标签\n",
    "    var_: ndarray of shape (n_classes, n_features) \n",
    "        每种类别的每个特征的方差\n",
    "    avg_: ndarray of shape (n_classes, n_features) \n",
    "        每种类别的每个特征的均值\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, priors=None, var_smoothing=1e-9):\n",
    "        self.class_prior_ = priors\n",
    "        self.var_smoothing = var_smoothing\n",
    "        self.classes_ = None\n",
    "        self.var_ = None\n",
    "        self.avg_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"拟合高斯贝叶斯模型以获得方差、均值等信息\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "        y:  ndarray of shape (n_samples,) 样本标签\n",
    "        \"\"\"\n",
    "        # 自适应计算类别概率\n",
    "        c = dict(Counter(y))\n",
    "        if self.class_prior_ is None:\n",
    "            self.class_prior_ = np.array(list(c.values())) / len(y)\n",
    "\n",
    "        # 获取已知数据集的分类标签\n",
    "        self.classes_ = np.array(list(c.keys()))\n",
    "\n",
    "        # 计算每种类别的每个特征的方差\n",
    "        self.var_ = np.array([X[y == label].var(axis=0)\n",
    "                              for label in self.classes_])\n",
    "        epsilon = self.var_smoothing * X.var(axis=0).max()\n",
    "        self.var_ += epsilon  # 添加附加值以调整方差\n",
    "\n",
    "        # 计算每种类别的每个特征的均值\n",
    "        self.avg_ = np.array([X[y == label].mean(axis=0)\n",
    "                              for label in self.classes_])\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"预测分类标签\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: ndarray of shape (n_samples,) 分类标签\n",
    "        \"\"\"\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "        return self.classes_[np.argmax(jll, axis=1)]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"预测归一化概率\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: ndarray of shape (n_samples, n_classes) 归一化概率\n",
    "        \"\"\"\n",
    "        return np.exp(self.predict_log_proba(X))\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        \"\"\"预测归一化概率(log)\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: ndarray of shape (n_samples, n_classes) 归一化概率(log)\n",
    "        \"\"\"\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "\n",
    "        # 归一化概率 e.g. log(pi / (p1+p2+...+pn)), i=1,2,...,n, n=n_classes\n",
    "        log_prob_x = logsumexp(jll, axis=1)\n",
    "        out = jll - np.atleast_2d(log_prob_x).T\n",
    "        return out\n",
    "\n",
    "    def _joint_log_likelihood(self, X):\n",
    "        \"\"\"计算联合概率(log)\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        joint_log_likelihood: ndarray of shape (n_samples, n_classes) 联合概率(log)\n",
    "        \"\"\"\n",
    "        joint_log_likelihood = []\n",
    "        for i in range(len(self.classes_)):\n",
    "            joint_i = np.log(self.class_prior_[i])\n",
    "            n_ij = -0.5 * np.sum(np.log(2. * np.pi * self.var_[i, :]))\n",
    "            n_ij -= 0.5 * np.sum((X-self.avg_[i, :]) ** 2 /\n",
    "                                 (self.var_[i, :]), 1)\n",
    "            joint_log_likelihood.append(joint_i + n_ij)\n",
    "\n",
    "        joint_log_likelihood = np.array(joint_log_likelihood).T\n",
    "        return joint_log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7913aa7",
   "metadata": {},
   "source": [
    "**<font color=black size=3.5>3.2 鸢尾花分类案例</font>**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6253415f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T11:58:32.556024Z",
     "start_time": "2021-09-21T11:58:32.545024Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b9022b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T11:58:32.572025Z",
     "start_time": "2021-09-21T11:58:32.559027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本文算法\n",
      "-------\n",
      "预测概率(log)\n",
      " [[ -676.68837308   -64.63814755     0.        ]\n",
      " [-3008.84065783  -360.48236167     0.        ]]\n",
      "预测概率\n",
      " [[1.31212014e-294 8.47245358e-029 1.00000000e+000]\n",
      " [0.00000000e+000 2.78291218e-157 1.00000000e+000]]\n",
      "预测类别\n",
      " [2 2]\n"
     ]
    }
   ],
   "source": [
    "# 本文算法\n",
    "myclf2 = MyGaussianNB()\n",
    "myclf2.fit(X, y)\n",
    "\n",
    "X_test2 = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "print('本文算法')\n",
    "print('-------')\n",
    "print('预测概率(log)\\n', myclf2.predict_log_proba(X_test2))\n",
    "print('预测概率\\n', myclf2.predict_proba(X_test2))\n",
    "print('预测类别\\n', myclf2.predict(X_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc256586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T11:58:32.588027Z",
     "start_time": "2021-09-21T11:58:32.574025Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn\n",
      "-------\n",
      "预测概率(log)\n",
      " [[ -676.68837308   -64.63814755     0.        ]\n",
      " [-3008.84065783  -360.48236167     0.        ]]\n",
      "预测概率\n",
      " [[1.31212014e-294 8.47245358e-029 1.00000000e+000]\n",
      " [0.00000000e+000 2.78291218e-157 1.00000000e+000]]\n",
      "预测类别\n",
      " [2 2]\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X, y)\n",
    "\n",
    "print('sklearn')\n",
    "print('-------')\n",
    "print('预测概率(log)\\n', clf2.predict_log_proba(X_test2))\n",
    "print('预测概率\\n', clf2.predict_proba(X_test2))\n",
    "print('预测类别\\n', clf2.predict(X_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b5e2f",
   "metadata": {},
   "source": [
    "可以看出，本文算法与sklearn得到的结果一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b149865",
   "metadata": {},
   "source": [
    "**<font size=4 color=black>参考</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d6dfc9",
   "metadata": {},
   "source": [
    "1 李航. (2012) 统计学习方法. 清华大学出版社, 北京.\n",
    "\n",
    "2 [sklearn.naive_bayes](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "342.667px",
    "left": "910px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
