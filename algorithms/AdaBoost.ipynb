{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07696ad",
   "metadata": {},
   "source": [
    "**<font size=5 color=black>AdaBoost</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819c3c5f",
   "metadata": {},
   "source": [
    "**1** 介绍AdaBoost算法二分类的基本原理\n",
    "\n",
    "**2** 介绍处理多分类问题的AdaBoost拓展算法SAMME\n",
    "\n",
    "**3** 手动实现AdaBoost算法及其拓展算法SAMME\n",
    "\n",
    "**4** 分别以简单二分类问题和鸢尾花多分类问题为例，对比本文算法与sklearn的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cae6aaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T02:31:10.365619Z",
     "start_time": "2021-09-22T02:31:08.964990Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b842a6e",
   "metadata": {},
   "source": [
    "**<font size=4 color=black>1 AdaBoost算法</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aba2df",
   "metadata": {},
   "source": [
    "**<font size=3.5 color=black>1.1 思想</font>**\n",
    "\n",
    "给定一个训练样本集，首先利用一个弱学习器（如深度为1的简单决策树）来训练；然后调整训练样本集的样本权重，再次\n",
    "\n",
    "利用弱学习器（可以与之前的一样，也可以不一样，重点在于”弱“，也就是要简单）来训练；最终，将所有的弱学习器\n",
    "\n",
    "按一定规则进行组合，得到集成学习器，即完成我们的目标。\n",
    "\n",
    "**在上述过程中，AdaBoost需要解决两个主要问题：**\n",
    "\n",
    "**1）**每一轮的样本权重如何确定？\n",
    "\n",
    "**2）**按什么规则组合弱分类器？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8487e157",
   "metadata": {},
   "source": [
    "**<font size=3.5 color=black>1.2 流程</font>**\n",
    "\n",
    "这里以二分类问题为例，给出AdaBoost算法的处理流程，并回答1.1中的两个问题。\n",
    "$\\rule[1pt]{23cm}{0.1em}$\n",
    "**输入**：训练数据集$D={(x_1, y_1),(x_2, y_2),...,(x_N, y_N)},x_i \\in R^n,y_i=\\{-1, 1\\}$；<br>\n",
    "**输出**：分类器$G(x)$\n",
    "\n",
    "**（1）**初始化训练数据的权值分布\n",
    "$w_1=(w_{1,1},w_{1,2},...,w_{1,N}),w_{1,i}=\\frac{1}{N},i=1,2,...,N\\tag{1}$\n",
    "\n",
    "**（2）**假设进行$m$轮训练，$m=1,2,...,M$\n",
    "\n",
    "**（3）**训练权值为$w_m$的数据集，得到弱分类器（或者叫基本分类器）\n",
    "$$G_m(x):x\\to\\{-1, 1\\}\\tag{2}$$\n",
    "\n",
    "**（4）**计算$G_m(x)$在训练数据集的分类误差率\n",
    "$$e_m=\\sum_{i=1}^{N}w_{mi}I(G_m(x_i) \\neq y_i)\\tag{3}$$\n",
    "可以理解为分类错误的样本的权值之和。\n",
    "\n",
    "**（5）**计算$G_m(x)$的系数\n",
    "$$\\alpha_m=\\frac{1}{2}ln\\frac{1-e_m}{e_m}\\tag{4}$$\n",
    "\n",
    "**（6）**更新样本权值\n",
    "$$w_{m+1,i}=(w_{m+1,1},w_{m+1,2},...,w_{m+1,N})\\tag{5}$$\n",
    "$$w_{m+1,i}=\\frac{w_{m,i}}{Z_m}exp(-\\alpha_m y_i G_m(x_i))\\tag{6}$$\n",
    "$$Z_m=\\sum_{i=1}^{N}w_{m,i}exp(-\\alpha_m y_i G_m(x_i))\\tag{7}$$\n",
    "这里引入$Z_m$的作用是对权值做归一化。\n",
    "\n",
    "**（7）**组合弱分类器（线性组合）\n",
    "$$f(x)=\\sum_{m=1}^{M}\\alpha_m G_m(x)\\tag{8}$$\n",
    "\n",
    "**（8）**最终分类器\n",
    "$$G(x)=sign(f(x)=sign(\\sum_{m=1}^{M}\\alpha_m G_m(x))\\tag{9}$$\n",
    "$\\rule[1pt]{23cm}{0.1em}$\n",
    "**<font size=3.5 color=red>几点说明：</font>**\n",
    "\n",
    "**（1）**初始的每个样本的权值是相等的，相当于每个样本在基本分类器学习中的作用相同，也就保证第一轮是在原始数据上学习$G(x_1)$；\\\n",
    "**（2）**公式(6)可以进一步写成：\n",
    "$$ w_{m+1,i}=\\left\\{\n",
    "\\begin{aligned}\n",
    "\\frac{w_{m,i}}{Z_m}e^{-\\alpha_m},G_m(x_i)=y_i \\\\\n",
    "\\frac{w_{m,i}}{Z_m}e^{\\alpha_m},G_m(x_i) \\neq y_i \n",
    "\\end{aligned}\n",
    "\\right.\n",
    "\\tag{10}$$\\\n",
    "可以看出，AdaBoost每一轮对样本权值的更新是放大分类错误的样本权值，缩小分类正确的样本权值，以使得误分类样本\n",
    "\n",
    "在下一轮的学习中起更大的作用。\n",
    "\n",
    "**（3）**AdaBoost对基本分类器的组合方式是线性组合。由公式(4)可以看出，基本分类器的分类误差率$e_m$越小，$G_m(x)$的系数$\\alpha_m$越大，即在组合时对于分类效果好的基本分类器给予更大的权重。\n",
    "\n",
    "**（4）**AdaBoost主要处理二分类问题，一般不用于多分类问题。针对多分类问题更多的采用SAMME或SAMME.R算法，\n",
    "\n",
    "详细可以参考[Multi-class AdaBoost](https://www.intlpress.com/site/pub/pages/journals/items/sii/content/vols/0002/0003/a008/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc9e46",
   "metadata": {},
   "source": [
    "**<font size=3.5 color=black>1.3 相关证明</font>**\n",
    "\n",
    "AdaBoost算法可以解释为模型为加法模型、损失函数为指数函数、学习算法为前向分布算法的二类分类学习方法。\n",
    "\n",
    "详细证明见[1]。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e277ba",
   "metadata": {},
   "source": [
    "**<font size=4 color=black>2 SAMME算法</font>**\n",
    "\n",
    "SAMME算法的提出是为了解决AdaBoost算法难以处理多分类任务这一问题，其基本思想与AdaBoost算法相同，只是在\n",
    "\n",
    "(4)、(6)、(8)、(9)公式上有一些差异，下面给出相关公式细节。\n",
    "\n",
    "**<font size=3.5 color=black>2.1 SAMME算法中的几个重要公式</font>**\n",
    "\n",
    "**（1）**$G_m(x)$的系数\n",
    "$$\\alpha_m=\\frac{1}{2}ln\\frac{1-e_m}{e_m}+ln(K-1)\\tag{11}$$\n",
    "$K$为训练数据集中样本的类别个数，当$K=2$时，等价于公式(4)。\n",
    "\n",
    "**（2）**样本权值更新\n",
    "$$w_{m+1,i}=\\frac{w_{m,i}}{Z_m}exp(\\alpha_m I(y_{pred} \\neq y_{truth}))\\tag{12}$$\n",
    "$$Z_m=\\sum_{i=1}^{N}w_{m,i}exp(\\alpha_m I(y_{pred} \\neq y_{truth}))\\tag{13}$$\n",
    "\n",
    "**（3）**预测\n",
    "$$G(x)=\\mathop {argmax} \\limits_{k} \\sum_{m=1}^{M}\\alpha_m I(G_m(x)=k)\\tag{14}$$\n",
    "\n",
    "**<font size=3.5 color=black>2.2 SAMME算法和AdaBoost算法的代码说明</font>**\n",
    "\n",
    "**（1）**为便于理解，本文在编写代码过程中尽可能按照给出的公式来实现，因此应用AdaBoost算法需要预先对二分类数据的标签设置为$\\{-1, 1\\}$，但需要清楚实际这并不是一项必要的工作，可以改写部分代码来处理这一问题。\n",
    "\n",
    "**（2）**SAMME算法也可以进行二分类。因此在调用时请注意：二分类问题可以选择算法有AdaBoost和SAMME，多分类问\n",
    "\n",
    "题仅可选择SAMME。\n",
    "\n",
    "**（3）**由于本文重点研究AdaBoost算法的学习流程，对于基本分类器的实现借助于[sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)，\n",
    "\n",
    "可以参考本项目的**DecisionTree.ipynb**部分了解更多。\n",
    "\n",
    "**（4）**本文仅限于帮助学习相关算法的基础理论，若想要更深入地学习，可以参考[sklearn.ensemble.AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "\n",
    "及实现源码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6651cc9f",
   "metadata": {},
   "source": [
    "**<font size=4 color=black>3 手动实现AdaBoost算法和SAMME算法</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fce5406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T02:31:10.396619Z",
     "start_time": "2021-09-22T02:31:10.368617Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyAdaBoostClassifier(object):\n",
    "    \"\"\"AdaBoost分类器   \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator: class \n",
    "        基分类器 默认为DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "    n_estimators: int \n",
    "        基分类器的个数\n",
    "    learning_rate: float\n",
    "        用于调整每个基分类器的权重，其值越大，基分类器的作用越大，默认值为1\n",
    "    algorithm: \n",
    "        {'AdaBoost','SAMME'} 默认'SAMME'\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_: ndarray of shape (n_classes_,)\n",
    "        数据集中的样本类别\n",
    "    n_classes_: int\n",
    "        数据集中的样本类别的个数\n",
    "    estimators_: list of classifiers\n",
    "        每一轮训练的基分类器\n",
    "    estimator_weights_: ndarray of shape (n_estimators_,)\n",
    "        基分类器的权值\n",
    "    estimator_errors_: ndarray of shape (n_estimators_,)\n",
    "        基分类器的分类误差率\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_estimator=DecisionTreeClassifier,\n",
    "                 n_estimators=3, learning_rate=1.0, algorithm='SAMME'):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.algorithm = algorithm\n",
    "        self.classes_ = None\n",
    "        self.n_classes_ = None\n",
    "        self.estimators_ = []\n",
    "        self.estimator_weights_ = []\n",
    "        self.estimator_errors_ = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"训练分类器\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "        y: ndarray of shape (n_samples,) 样本标签\n",
    "        \"\"\"\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "\n",
    "        # 初始化样本权值\n",
    "        w = np.array([1 / len(y)] * len(y))\n",
    "        for i in range(self.n_estimators):\n",
    "            # 初始化基分类器\n",
    "            estimator = self.base_estimator(max_depth=1, random_state=42)\n",
    "            # 训练基分类器\n",
    "            estimator.fit(X, y, sample_weight=w)\n",
    "            # 基分类器预测\n",
    "            y_pre = estimator.predict(X)\n",
    "            # 计算基分类器的分类误差率\n",
    "            e = np.sum((y_pre != y) * w)\n",
    "\n",
    "            # 计算基分类器权值并更新样本权值\n",
    "            if self.algorithm == 'SAMME':\n",
    "                alpha = self.learning_rate * np.log((1-e) / e) + \\\n",
    "                    np.log(self.n_classes_-1)\n",
    "                w = w * np.exp(alpha * (y_pre != y))\n",
    "                w = w / np.sum(w)\n",
    "            elif self.algorithm == 'AdaBoost':\n",
    "                alpha = 0.5 * np.log((1-e) / e)\n",
    "                w = w * np.exp(-alpha * y * y_pre)\n",
    "                w = w / np.sum(w)\n",
    "\n",
    "            self.estimators_.append(estimator)\n",
    "            self.estimator_weights_.append(alpha)\n",
    "            self.estimator_errors_.append(e)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"预测分类标签\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray of shape (n_samples, n_features) 样本向量\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: ndarray of shape (n_samples,) 分类标签\n",
    "        \"\"\"\n",
    "        classes_ = self.classes_[:, np.newaxis]\n",
    "        n_classes_ = self.n_classes_\n",
    "\n",
    "        # 集成分类器预测\n",
    "        if n_classes_ == 2:\n",
    "            pred = np.zeros(X.shape[0])\n",
    "            for alpha, estimator in zip(self.estimator_weights_, self.estimators_):\n",
    "                pred += alpha * estimator.predict(X)\n",
    "            return np.sign(pred)\n",
    "        else:\n",
    "            pred = sum((estimator.predict(X) == classes_).T * alpha\n",
    "                       for estimator, alpha in zip(self.estimators_, self.estimator_weights_))\n",
    "            # 这里参考sklearn进行归一化，上文公式未给出，但不影响输出结果\n",
    "            pred /= np.sum(self.estimator_weights_)  \n",
    "            return self.classes_.take(np.argmax(pred, axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d76b6b5",
   "metadata": {},
   "source": [
    "**<font size=4 colot=black>3 案例</font>**\n",
    "\n",
    "**<font size=3.5 colot=black>3.1 二分类</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "446ec941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T02:31:10.411620Z",
     "start_time": "2021-09-22T02:31:10.398620Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "X1 = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).reshape(-1, 1)\n",
    "y1 = np.array([1, 1, 1, -1, -1, -1, 1, 1, 1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96da43fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T02:31:10.443622Z",
     "start_time": "2021-09-22T02:31:10.413620Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本文算法-AdaBoost\n",
      "-----------------\n",
      "集成分类器预测结果：\n",
      " [ 1.  1.  1. -1. -1. -1.  1.  1.  1. -1.]\n",
      "子分类器权重：\n",
      " [0.4236489301936017, 0.6496414920651304, 0.752038698388137]\n",
      "子分类器误差率：\n",
      " [0.30000000000000004, 0.21428571428571427, 0.18181818181818185]\n"
     ]
    }
   ],
   "source": [
    "# 本文算法-AdaBoost\n",
    "myada = MyAdaBoostClassifier(n_estimators=3, algorithm='AdaBoost')\n",
    "myada.fit(X1, y1)\n",
    "\n",
    "print('本文算法-AdaBoost')\n",
    "print('-----------------')\n",
    "print('集成分类器预测结果：\\n', myada.predict(X1))\n",
    "print('子分类器权重：\\n', myada.estimator_weights_)\n",
    "print('子分类器误差率：\\n', myada.estimator_errors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33019a23",
   "metadata": {},
   "source": [
    "可以看出使用AdaBoost算法得到的结果与文献[1]中所对应的例子的结果一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9fb9b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T02:31:10.473628Z",
     "start_time": "2021-09-22T02:31:10.446630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本文算法-SAMME\n",
      "-------------\n",
      "集成分类器预测结果：\n",
      " [ 1.  1.  1. -1. -1. -1.  1.  1.  1. -1.]\n",
      "子分类器权重：\n",
      " [0.8472978603872034, 1.2992829841302609, 1.504077396776274]\n",
      "子分类器误差率：\n",
      " [0.30000000000000004, 0.21428571428571427, 0.18181818181818182]\n"
     ]
    }
   ],
   "source": [
    "# 本文算法-SAMME\n",
    "myada = MyAdaBoostClassifier(n_estimators=3, algorithm='SAMME')\n",
    "myada.fit(X1, y1)\n",
    "\n",
    "print('本文算法-SAMME')\n",
    "print('-------------')\n",
    "print('集成分类器预测结果：\\n', myada.predict(X1))\n",
    "print('子分类器权重：\\n', myada.estimator_weights_)\n",
    "print('子分类器误差率：\\n', myada.estimator_errors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8985a823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T02:31:10.505630Z",
     "start_time": "2021-09-22T02:31:10.476627Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn\n",
      "-------\n",
      "集成分类器预测结果：\n",
      " [ 1  1  1 -1 -1 -1  1  1  1 -1]\n",
      "子分类器权重：\n",
      " [0.84729786 1.29928298 1.5040774 ]\n",
      "子分类器误差率：\n",
      " [0.3        0.21428571 0.18181818]\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n",
    "                         n_estimators=3, algorithm='SAMME')\n",
    "ada.fit(X1, y1)\n",
    "\n",
    "print('sklearn')\n",
    "print('-------')\n",
    "print('集成分类器预测结果：\\n', ada.predict(X1))\n",
    "print('子分类器权重：\\n', ada.estimator_weights_)\n",
    "print('子分类器误差率：\\n', ada.estimator_errors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d0702",
   "metadata": {},
   "source": [
    "二分类实例的本文算法与sklearn得到的结果一致。但sklearn的实现细节与本文有所差异，读者可以自行查阅源码了解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7208dc14",
   "metadata": {},
   "source": [
    "**<font size=3.5 colot=black>3.2 多分类</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b5096f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T02:31:10.521628Z",
     "start_time": "2021-09-22T02:31:10.509630Z"
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X2 = iris.data\n",
    "y2 = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ba9b31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T02:31:10.553631Z",
     "start_time": "2021-09-22T02:31:10.525631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本文算法\n",
      "-------\n",
      "集成分类器预测结果：\n",
      " [0 1 2]\n",
      "子分类器权重：\n",
      " [1.386294361119891, 2.2094946699280333, 2.742455876638902]\n",
      "子分类器误差率：\n",
      " [0.33333333333333326, 0.18000000000000002, 0.11412225233363443]\n"
     ]
    }
   ],
   "source": [
    "# 本文算法\n",
    "myada = MyAdaBoostClassifier(n_estimators=3, algorithm='SAMME')\n",
    "myada.fit(X2, y2)\n",
    "\n",
    "print('本文算法')\n",
    "print('-------')\n",
    "print('集成分类器预测结果：\\n', myada.predict(X2[[0, 50, 100], :]))\n",
    "print('子分类器权重：\\n', myada.estimator_weights_)\n",
    "print('子分类器误差率：\\n', myada.estimator_errors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb9c4a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T02:31:10.585633Z",
     "start_time": "2021-09-22T02:31:10.556633Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn\n",
      "-------\n",
      "集成分类器预测结果：\n",
      " [0 1 2]\n",
      "子分类器权重：\n",
      " [1.38629436 2.20949467 2.74245588]\n",
      "子分类器误差率：\n",
      " [0.33333333 0.18       0.11412225]\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n",
    "                         n_estimators=3, algorithm='SAMME')\n",
    "ada.fit(X2, y2)\n",
    "\n",
    "print('sklearn')\n",
    "print('-------')\n",
    "print('集成分类器预测结果：\\n', ada.predict(X2[[0, 50, 100], :]))\n",
    "print('子分类器权重：\\n', ada.estimator_weights_)\n",
    "print('子分类器误差率：\\n', ada.estimator_errors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27067433",
   "metadata": {},
   "source": [
    "多分类实例的本文算法与sklearn的结果一致。在该部分的代码实现过程中，参考了sklearn对应源码的部分实现细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9426f4",
   "metadata": {},
   "source": [
    "**<font color=black size=4>参考</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5e349",
   "metadata": {},
   "source": [
    "1 李航. (2012) 统计学习方法. 清华大学出版社, 北京.\n",
    "\n",
    "2 [sklearn.ensemble.AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "254.667px",
    "left": "910px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
